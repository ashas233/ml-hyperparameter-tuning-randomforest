{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJjB1ypvRkg_",
        "outputId": "733cb152-2878-4168-e5e8-a515eb7ff78f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Baseline RandomForest ===\n",
            "CV (accuracy) mean: 0.4744\n",
            "Test (accuracy): 0.5500\n",
            "\n",
            "=== Grid Search Results ===\n",
            "Best params: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Best CV (accuracy) mean: 0.4986\n",
            "\n",
            "=== Test Set Performance (Tuned) ===\n",
            "Accuracy: 0.5500\n",
            "\n",
            "Classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.44      0.47         9\n",
            "           1       0.58      0.64      0.61        11\n",
            "\n",
            "    accuracy                           0.55        20\n",
            "   macro avg       0.54      0.54      0.54        20\n",
            "weighted avg       0.55      0.55      0.55        20\n",
            "\n",
            "\n",
            "=== Before vs After (summary) ===\n",
            "CV (accuracy)   - Baseline: 0.4744 | Tuned: 0.4986\n",
            "Test (accuracy) - Baseline: 0.5500 | Tuned: 0.5500\n"
          ]
        }
      ],
      "source": [
        "\n",
        "TASK = \"classification\"\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, classification_report, r2_score, mean_squared_error\n",
        ")\n",
        "import warnings; warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "def is_classification_task(TASK): return TASK.lower().startswith(\"class\")\n",
        "\n",
        "X = np.random.rand(100, 10)\n",
        "if is_classification_task(TASK):\n",
        "    y = np.random.randint(0, 2, 100)\n",
        "else:\n",
        "    y = np.random.rand(100)\n",
        "\n",
        "\n",
        "stratify_arg = None\n",
        "if is_classification_task(TASK):\n",
        "\n",
        "    try:\n",
        "\n",
        "        stratify_arg = y\n",
        "    except Exception:\n",
        "        stratify_arg = None\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=stratify_arg\n",
        ")\n",
        "\n",
        "\n",
        "if is_classification_task(TASK):\n",
        "    base_model = RandomForestClassifier(\n",
        "        n_estimators=100, random_state=42, n_jobs=-1\n",
        "    )\n",
        "    scoring = \"accuracy\"\n",
        "else:\n",
        "    base_model = RandomForestRegressor(\n",
        "        n_estimators=100, random_state=42, n_jobs=-1\n",
        "    )\n",
        "    scoring = \"r2\"\n",
        "\n",
        "\n",
        "baseline_cv = cross_val_score(base_model, X_train, y_train, cv=3, scoring=scoring, n_jobs=-1)\n",
        "baseline_cv_mean = baseline_cv.mean()\n",
        "\n",
        "# Fit baseline and evaluate on test\n",
        "base_model.fit(X_train, y_train)\n",
        "if is_classification_task(TASK):\n",
        "    y_pred_test_base = base_model.predict(X_test)\n",
        "    baseline_test_metric = accuracy_score(y_test, y_pred_test_base)\n",
        "else:\n",
        "    y_pred_test_base = base_model.predict(X_test)\n",
        "    baseline_test_metric = r2_score(y_test, y_pred_test_base)\n",
        "\n",
        "print(\"=== Baseline RandomForest ===\")\n",
        "print(f\"CV ({scoring}) mean: {baseline_cv_mean:.4f}\")\n",
        "print(f\"Test ({scoring}): {baseline_test_metric:.4f}\\n\")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 10, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "Estimator = RandomForestClassifier if is_classification_task(TASK) else RandomForestRegressor\n",
        "grid = GridSearchCV(\n",
        "    Estimator(random_state=42, n_jobs=-1),\n",
        "    param_grid=param_grid,\n",
        "    scoring=scoring,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=0,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"=== Grid Search Results ===\")\n",
        "print(f\"Best params: {grid.best_params_}\")\n",
        "print(f\"Best CV ({scoring}) mean: {grid.best_score_:.4f}\\n\")\n",
        "\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "y_pred_test_best = best_model.predict(X_test)\n",
        "\n",
        "if is_classification_task(TASK):\n",
        "    tuned_test_metric = accuracy_score(y_test, y_pred_test_best)\n",
        "    print(\"=== Test Set Performance (Tuned) ===\")\n",
        "    print(f\"Accuracy: {tuned_test_metric:.4f}\")\n",
        "    print(\"\\nClassification report:\\n\")\n",
        "    print(classification_report(y_test, y_pred_test_best))\n",
        "else:\n",
        "    tuned_test_metric = r2_score(y_test, y_pred_test_best)\n",
        "    mse = mean_squared_error(y_test, y_pred_test_best)\n",
        "    print(\"=== Test Set Performance (Tuned) ===\")\n",
        "    print(f\"R^2: {tuned_test_metric:.4f}\")\n",
        "    print(f\"MSE: {mse:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\n=== Before vs After (summary) ===\")\n",
        "print(f\"CV ({scoring})   - Baseline: {baseline_cv_mean:.4f} | Tuned: {grid.best_score_:.4f}\")\n",
        "print(f\"Test ({scoring}) - Baseline: {baseline_test_metric:.4f} | Tuned: {tuned_test_metric:.4f}\")"
      ]
    }
  ]
}